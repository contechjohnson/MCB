/**
 * Centner Wellness Content Outlier Analysis - Full Orchestration
 *
 * This script handles the complete workflow:
 * 1. Scrapes real Instagram posts from top wellness/biohacking creators via Apify
 * 2. Runs content outlier detection with cross-niche scoring
 * 3. Generates caption variants via OpenAI
 * 4. Exports to Google Sheets with formatting
 *
 * Usage: node execution/run-centner-content-analysis.js
 */

const { ApifyClient } = require('apify-client');
const { exec } = require('child_process');
const fs = require('fs');
const path = require('path');
require('dotenv').config({ path: '.env.local' });

// Top Centner wellness creators (from research)
const CREATORS = [
  { handle: 'kaylabarnes', followers: 547300 },
  { handle: 'davidsinclairphd', followers: 746700 },
  { handle: 'drpoonamdesai', followers: 319500 },
  { handle: 'nathalieniddam', followers: 64100 },
  { handle: 'dr.longevity', followers: 182700 },
];

async function scrapeInstagramPosts() {
  console.log('ğŸ” Scraping Instagram posts via Apify...\n');

  const client = new ApifyClient({ token: process.env.APIFY_TOKEN });

  const allData = [];

  for (const creator of CREATORS) {
    console.log(`ğŸ“¦ Scraping @${creator.handle}...`);

    try {
      // Use Apify Instagram Post Scraper actor
      const input = {
        username: [creator.handle],  // Fixed: singular 'username' not 'usernames'
        resultsLimit: 30, // Last 30 posts
      };

      // Run the actor
      const run = await client.actor('apify/instagram-post-scraper').call(input);

      // Fetch results
      const { items } = await client.dataset(run.defaultDatasetId).listItems();

      console.log(`   âœ… Found ${items.length} posts\n`);

      // Format data
      allData.push({
        handle: creator.handle,
        followers: creator.followers,
        bio: `Instagram creator @${creator.handle}`,
        posts: items.map((post) => ({
          url: post.url,
          caption: post.caption || '',
          likes: post.likesCount || 0,
          comments: post.commentsCount || 0,
          timestamp: post.timestamp,
          type: post.type || 'Photo',
          thumbnail_url: post.displayUrl || '',
          _creatorHandle: creator.handle,
        })),
      });
    } catch (error) {
      console.error(`   âŒ Error scraping @${creator.handle}: ${error.message}\n`);
    }
  }

  // Save scraped data
  const outputPath = path.join(__dirname, '../outputs/instagram_data_centner_real.json');
  fs.writeFileSync(outputPath, JSON.stringify(allData, null, 2));

  console.log(`ğŸ’¾ Saved ${allData.length} creators to: ${outputPath}\n`);

  return allData;
}

async function runAnalysis(scrapedData) {
  console.log('ğŸ“Š Running content outlier detection on REAL scraped data...\n');

  // The data is already saved to instagram_data_centner_real.json
  // Now we need to create a way for the analysis script to load it
  // For now, let's pass the creator handles that were scraped
  const handles = scrapedData.map(c => '@' + c.handle).join(',');

  return new Promise((resolve, reject) => {
    const cmd = `node execution/content-outlier-detection.js --handles "${handles}"`;

    exec(cmd, { cwd: path.join(__dirname, '..'), maxBuffer: 10 * 1024 * 1024 }, (error, stdout, stderr) => {
      if (error) {
        console.error(`âŒ Analysis failed: ${error.message}`);
        reject(error);
        return;
      }

      console.log(stdout);
      if (stderr) console.error(stderr);

      resolve();
    });
  });
}

async function exportToGoogleSheets(csvPath) {
  console.log('\nğŸ“¤ Exporting to Google Sheets...\n');

  // Read CSV
  const csvContent = fs.readFileSync(csvPath, 'utf8');
  const lines = csvContent.split('\n');
  const headers = lines[0].split(',');

  const rows = lines.slice(1).filter(l => l.trim()).map(line => {
    // Simple CSV parsing (may need enhancement for complex cases)
    return line.split(',');
  });

  console.log(`âœ… Parsed ${rows.length} outliers from CSV\n`);

  // TODO: Use Google Workspace MCP to create spreadsheet
  // For now, return CSV path
  console.log('âš ï¸  Google Sheets export pending - CSV ready at:');
  console.log(`   ${csvPath}\n`);

  return csvPath;
}

async function main() {
  console.log('ğŸ¬ CENTNER WELLNESS - Content Outlier Analysis\n');
  console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n');

  try {
    // Step 1: Scrape real Instagram data
    const scrapedData = await scrapeInstagramPosts();

    // Step 2: Run analysis
    await runAnalysis(scrapedData);

    // Step 3: Export to Google Sheets
    const csvPath = path.join(__dirname, '../outputs/content_outliers_centner_latest.csv');
    await exportToGoogleSheets(csvPath);

    console.log('â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n');
    console.log('âœ… Analysis complete!\n');

  } catch (error) {
    console.error(`\nâŒ Fatal error: ${error.message}\n`);
    process.exit(1);
  }
}

if (require.main === module) {
  main();
}

module.exports = { scrapeInstagramPosts, exportToGoogleSheets };
